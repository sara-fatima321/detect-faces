{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 2.3.7, however version 2.5.1 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7935/\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "Interface loading below...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7935/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a47df33dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>, 'http://127.0.0.1:7935/', None)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 67  82  51]\n",
      "  [ 77  93  54]\n",
      "  [115 133  81]\n",
      "  ...\n",
      "  [165 168  97]\n",
      "  [162 164  99]\n",
      "  [159 161  96]]\n",
      "\n",
      " [[ 80  94  58]\n",
      "  [ 81  98  54]\n",
      "  [101 121  62]\n",
      "  ...\n",
      "  [168 171 100]\n",
      "  [155 158  91]\n",
      "  [141 143  78]]\n",
      "\n",
      " [[ 72  85  39]\n",
      "  [ 72  89  34]\n",
      "  [ 81 101  32]\n",
      "  ...\n",
      "  [171 174 105]\n",
      "  [152 155  86]\n",
      "  [131 134  67]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[166 176 178]\n",
      "  [166 176 178]\n",
      "  [166 176 178]\n",
      "  ...\n",
      "  [239 239 237]\n",
      "  [239 239 237]\n",
      "  [239 239 237]]\n",
      "\n",
      " [[165 175 177]\n",
      "  [165 175 177]\n",
      "  [165 175 177]\n",
      "  ...\n",
      "  [238 238 236]\n",
      "  [238 238 236]\n",
      "  [238 238 236]]\n",
      "\n",
      " [[165 175 177]\n",
      "  [165 175 177]\n",
      "  [165 175 177]\n",
      "  ...\n",
      "  [237 237 235]\n",
      "  [237 237 235]\n",
      "  [237 237 235]]] image here\n",
      "Nose tip:\n",
      "x: 0.4611522853374481\n",
      "y: 0.43626275658607483\n",
      "\n",
      "label_id: 0\n",
      "score: 0.725614607334137\n",
      "location_data {\n",
      "  format: RELATIVE_BOUNDING_BOX\n",
      "  relative_bounding_box {\n",
      "    xmin: 0.405670702457428\n",
      "    ymin: 0.3337840735912323\n",
      "    width: 0.11572670936584473\n",
      "    height: 0.1739441454410553\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.4397861659526825\n",
      "    y: 0.3962065279483795\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.489473819732666\n",
      "    y: 0.3937482535839081\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.4611522853374481\n",
      "    y: 0.43626275658607483\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.4652278423309326\n",
      "    y: 0.4665554463863373\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.4248610734939575\n",
      "    y: 0.4047127068042755\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.5262311697006226\n",
      "    y: 0.396214097738266\n",
      "  }\n",
      "}\n",
      "\n",
      "[[[252 254 249]\n",
      "  [251 249 250]\n",
      "  [255 251 255]\n",
      "  ...\n",
      "  [233 235 234]\n",
      "  [233 235 234]\n",
      "  [233 235 234]]\n",
      "\n",
      " [[253 255 250]\n",
      "  [252 250 251]\n",
      "  [255 251 255]\n",
      "  ...\n",
      "  [233 235 234]\n",
      "  [233 235 234]\n",
      "  [233 235 234]]\n",
      "\n",
      " [[254 255 253]\n",
      "  [253 251 252]\n",
      "  [255 252 253]\n",
      "  ...\n",
      "  [233 235 234]\n",
      "  [233 235 234]\n",
      "  [233 235 234]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[100  57  23]\n",
      "  [ 99  56  22]\n",
      "  [ 98  55  21]\n",
      "  ...\n",
      "  [193 203 205]\n",
      "  [194 204 206]\n",
      "  [194 204 206]]\n",
      "\n",
      " [[104  61  27]\n",
      "  [103  60  26]\n",
      "  [102  59  25]\n",
      "  ...\n",
      "  [193 203 205]\n",
      "  [194 204 206]\n",
      "  [194 204 206]]\n",
      "\n",
      " [[102  59  24]\n",
      "  [101  58  23]\n",
      "  [100  57  22]\n",
      "  ...\n",
      "  [193 203 205]\n",
      "  [194 204 206]\n",
      "  [194 204 206]]] image here\n",
      "Nose tip:\n",
      "x: 0.39298132061958313\n",
      "y: 0.3381178677082062\n",
      "\n",
      "label_id: 0\n",
      "score: 0.5999164581298828\n",
      "location_data {\n",
      "  format: RELATIVE_BOUNDING_BOX\n",
      "  relative_bounding_box {\n",
      "    xmin: 0.2990037500858307\n",
      "    ymin: 0.21592015027999878\n",
      "    width: 0.14236238598823547\n",
      "    height: 0.21618029475212097\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.35381489992141724\n",
      "    y: 0.28067687153816223\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.3900403678417206\n",
      "    y: 0.28655675053596497\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.39298132061958313\n",
      "    y: 0.3381178677082062\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.37721413373947144\n",
      "    y: 0.3811716139316559\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.27802932262420654\n",
      "    y: 0.2864104211330414\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.37557756900787354\n",
      "    y: 0.2981548607349396\n",
      "  }\n",
      "}\n",
      "\n",
      "Nose tip:\n",
      "x: 0.6096754670143127\n",
      "y: 0.46960148215293884\n",
      "\n",
      "label_id: 0\n",
      "score: 0.5569804310798645\n",
      "location_data {\n",
      "  format: RELATIVE_BOUNDING_BOX\n",
      "  relative_bounding_box {\n",
      "    xmin: 0.5620973706245422\n",
      "    ymin: 0.3598189651966095\n",
      "    width: 0.12788426876068115\n",
      "    height: 0.19420966506004333\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.5975816249847412\n",
      "    y: 0.4179022014141083\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.6522778868675232\n",
      "    y: 0.4340948164463043\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.6096754670143127\n",
      "    y: 0.46960148215293884\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.608252227306366\n",
      "    y: 0.5090166330337524\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.5859270691871643\n",
      "    y: 0.4261064827442169\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.6977634429931641\n",
      "    y: 0.4612490236759186\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Socket exception: An existing connection was forcibly closed by the remote host (10054)\n",
      "Socket exception: An existing connection was forcibly closed by the remote host (10054)\n",
      "Socket exception: An existing connection was forcibly closed by the remote host (10054)\n",
      "Socket exception: An existing connection was forcibly closed by the remote host (10054)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "import gradio as gr\n",
    "\n",
    "# For static images:\n",
    "def detect(img):\n",
    "    IMAGE_FILES = [\"D:\\BERT\\mask images\\dd.jpg\"]\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=1, min_detection_confidence=0.5) as face_detection:\n",
    "        for idx, file in enumerate(IMAGE_FILES):\n",
    "            image = img\n",
    "            print(image, 'image here')\n",
    "            # Convert the BGR image to RGB and process it with MediaPipe Face Detection.\n",
    "            # results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "            # Draw face detections of each face.\n",
    "            if not results.detections:\n",
    "                continue\n",
    "#            annotated_image = image.copy()\n",
    "            annotated_image = image.copy()\n",
    "            h,w,c = image.shape\n",
    "\n",
    "            \n",
    "            for detection in results.detections:\n",
    "                print('Nose tip:')\n",
    "                print(mp_face_detection.get_key_point(\n",
    "                    detection, mp_face_detection.FaceKeyPoint.NOSE_TIP))\n",
    "                # bbox = detection.location_data.relative_bounding_box\n",
    "                # # bbox_points = {\n",
    "                #     \"xmin\" : int(bbox.xmin * width),\n",
    "                #     \"ymin\" : int(bbox.ymin * height),\n",
    "                #     \"xmax\" : int(bbox.width * width + bbox.xmin * width),\n",
    "                #     \"ymax\" : int(bbox.height * height + bbox.ymin * height)\n",
    "                # }\n",
    "                print(detection)\n",
    "                data = detection.location_data.relative_bounding_box\n",
    "                xleft = data.xmin*w\n",
    "                xleft = int(xleft)\n",
    "                xtop = data.ymin*h\n",
    "                xtop = int(xtop)\n",
    "                xright = data.width*w + xleft\n",
    "                xright = int(xright)\n",
    "                xbottom = data.height*h + xtop\n",
    "                xbottom = int(xbottom)\n",
    "                cv2.rectangle(annotated_image, (xleft, xtop), (xright, xbottom), (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # x_max = 0\n",
    "                # y_max = 0\n",
    "                # x_min = w\n",
    "                # y_min = h\n",
    "                \n",
    "                # x, y = int(detection.location_data.relative_bounding_box.xmin * w), int(detection.location_data.relative_bounding_box.ymin * h)\n",
    "                # if x > x_max:\n",
    "                #     x_max = x\n",
    "                # if x < x_min:\n",
    "                #     x_min = x\n",
    "                # if y > y_max:\n",
    "                #     y_max = y\n",
    "                # if y < y_min:\n",
    "                #     y_min = y\n",
    "                # cv2.rectangle(annotated_image, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
    "        \n",
    "                # mp_drawing.draw_detection(annotated_image, detection)\n",
    "            ##cv2.imwrite('./new' + str(idx) + '.png', annotated_image)\n",
    "            return annotated_image\n",
    "\n",
    "\n",
    "#img = gr.inputs.Image(shape=(100, 100), image_mode='L', invert_colors=False, source=\"upload\")\n",
    "img = gr.inputs.Image(source=\"upload\")\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn = detect, \n",
    "    inputs = img, \n",
    "    outputs = 'image',\n",
    ")\n",
    "iface.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
